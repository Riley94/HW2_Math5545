{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.635385</td>\n",
       "      <td>-0.245113</td>\n",
       "      <td>-5.759791</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.135634</td>\n",
       "      <td>11.363122</td>\n",
       "      <td>2.552492</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.475013</td>\n",
       "      <td>-3.697097</td>\n",
       "      <td>1.828806</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.722604</td>\n",
       "      <td>11.112576</td>\n",
       "      <td>-2.963583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.409597</td>\n",
       "      <td>-2.151576</td>\n",
       "      <td>-9.005747</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a          b         c  d\n",
       "0 -5.635385  -0.245113 -5.759791  1\n",
       "1 -5.135634  11.363122  2.552492  0\n",
       "2  4.475013  -3.697097  1.828806  1\n",
       "3 -3.722604  11.112576 -2.963583  0\n",
       "4 -4.409597  -2.151576 -9.005747  1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate dataset\n",
    "n = 40000\n",
    "a = np.random.uniform(-10, 10, n)\n",
    "b = np.random.uniform(-5, 15, n)\n",
    "c = np.random.uniform(-20, 5, n)\n",
    "discriminant = b**2 - 4*a*c\n",
    "# if discriminant is negative, the equation has no real roots\n",
    "d = (discriminant < 0).astype(int)\n",
    "\n",
    "# Ensure class balance (20%-40% ones)\n",
    "ones_ratio = np.mean(d)\n",
    "target_min, target_max = 0.2, 0.4\n",
    "if ones_ratio < target_min or ones_ratio > target_max:\n",
    "    zero_indices = np.where(d == 0)[0]\n",
    "    one_indices = np.where(d == 1)[0]\n",
    "    target_ones = int(n * np.random.uniform(target_min, target_max))\n",
    "\n",
    "    if len(one_indices) > target_ones:\n",
    "        drop_ones = np.random.choice(one_indices, len(one_indices) - target_ones, replace=False)\n",
    "        d[drop_ones] = 0\n",
    "    elif len(one_indices) < target_ones:\n",
    "        add_ones = np.random.choice(zero_indices, target_ones - len(one_indices), replace=False)\n",
    "        d[add_ones] = 1\n",
    "\n",
    "# Convert to DataFrame\n",
    "data = pd.DataFrame({'a': a, 'b': b, 'c': c, 'd': d})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validating Decision Tree...\n",
      "Decision Tree CV Accuracy: 0.9827\n",
      "Testing Decision Tree...\n",
      "Decision Tree Test Accuracy: 0.9826\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5070\n",
      "           1       0.97      0.98      0.98      2930\n",
      "\n",
      "    accuracy                           0.98      8000\n",
      "   macro avg       0.98      0.98      0.98      8000\n",
      "weighted avg       0.98      0.98      0.98      8000\n",
      "\n",
      "--------------------------------------------------\n",
      "Cross-Validating Neural Network...\n",
      "Neural Network CV Accuracy: 0.9962\n",
      "Testing Neural Network...\n",
      "Neural Network Test Accuracy: 0.9954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      5070\n",
      "           1       1.00      0.99      0.99      2930\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       1.00      0.99      1.00      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "--------------------------------------------------\n",
      "Cross-Validating Logistic Regression...\n",
      "Logistic Regression CV Accuracy: 0.8357\n",
      "Testing Logistic Regression...\n",
      "Logistic Regression Test Accuracy: 0.8350\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87      5070\n",
      "           1       0.81      0.72      0.76      2930\n",
      "\n",
      "    accuracy                           0.83      8000\n",
      "   macro avg       0.83      0.81      0.82      8000\n",
      "weighted avg       0.83      0.83      0.83      8000\n",
      "\n",
      "--------------------------------------------------\n",
      "Cross-Validating Random Forest...\n",
      "Random Forest CV Accuracy: 0.9902\n",
      "Testing Random Forest...\n",
      "Random Forest Test Accuracy: 0.9906\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5070\n",
      "           1       0.99      0.99      0.99      2930\n",
      "\n",
      "    accuracy                           0.99      8000\n",
      "   macro avg       0.99      0.99      0.99      8000\n",
      "weighted avg       0.99      0.99      0.99      8000\n",
      "\n",
      "--------------------------------------------------\n",
      "Cross-Validating XGBoost...\n",
      "XGBoost CV Accuracy: 0.9917\n",
      "Testing XGBoost...\n",
      "XGBoost Test Accuracy: 0.9914\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5070\n",
      "           1       0.99      0.99      0.99      2930\n",
      "\n",
      "    accuracy                           0.99      8000\n",
      "   macro avg       0.99      0.99      0.99      8000\n",
      "weighted avg       0.99      0.99      0.99      8000\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test sets\n",
    "X = data[['a', 'b', 'c']]\n",
    "y = data['d']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Use Stratified K-Fold Cross-Validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Standardize features for models that require it\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Models\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Neural Network\": MLPClassifier(hidden_layer_sizes=(32, 16), max_iter=1000, random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric=\"logloss\", random_state=42)\n",
    "}\n",
    "\n",
    "# Training and evaluation\n",
    "for name, model in models.items():\n",
    "    accuracies = []\n",
    "    print(f\"Cross-Validating {name}...\")\n",
    "    for train_index, val_index in kf.split(X_train, y_train):\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "        X_train_scaled_fold, X_val_scaled_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "        \n",
    "        if name in [\"Neural Network\", \"Logistic Regression\"]:\n",
    "            model.fit(X_train_scaled_fold, y_train_fold)\n",
    "            y_pred = model.predict(X_val_scaled_fold)\n",
    "        else:\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "            y_pred = model.predict(X_val_fold)\n",
    "        \n",
    "        acc = accuracy_score(y_val_fold, y_pred)\n",
    "        accuracies.append(acc)\n",
    "\n",
    "    print(f\"{name} CV Accuracy: {np.mean(accuracies):.4f}\")    \n",
    "    print(f\"Testing {name}...\")\n",
    "    if name in [\"Neural Network\", \"Logistic Regression\"]:  \n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name} Test Accuracy: {acc:.4f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HW2_Math5545",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
